{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a792b119",
   "metadata": {},
   "source": [
    "# Connecting to a Feature Store\n",
    "\n",
    "特征存储是传统机器学习的一个概念，它确保输入模型的数据是最新的和相关的。有关更多信息，请参见此处。\n",
    "\n",
    "在考虑将`LLM`应用程序投入生产时，这个概念非常重要。为了个性化`LLM`应用程序，您可能希望将`LLM`与有关特定用户的最新信息结合起来。特征存储是保持数据最新的好方法，`LangChain`提供了一种将该数据与`LLM`结合的简单方法。\n",
    "\n",
    "在此笔记本中，我们将展示如何将提示模板连接到特征存储。基本思想是从提示模板内部调用特征存储来检索值，然后将这些值格式化为提示。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad0b5edf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feast\n",
    "\n",
    "To start, we will use the popular open source feature store framework [Feast](https://github.com/feast-dev/feast).\n",
    "\n",
    "This assumes you have already run the steps in the README around getting started. We will build of off that example in getting started, and create and LLMChain to write a note to a specific driver regarding their up-to-date statistics.\n",
    "首先，我们将使用流行的开源特征存储框架 Feast。\n",
    "这假设您已经运行了`README`中关于入门的步骤。我们将在入门部分构建该示例，并创建和 LLMChain 以向特定驱动程序写入有关其最新统计数据的注释。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f02f6f3",
   "metadata": {},
   "source": [
    "### Load Feast Store\n",
    "\n",
    "Again, this should be set up according to the instructions in the Feast README\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1a452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feast import FeatureStore\n",
    "import os\n",
    "\n",
    "# You may need to update the path depending on where you stored it\n",
    "feast_repo_path = os.path.abspath(\"feast/prompts_demo/feature_repo\")\n",
    "store = FeatureStore(repo_path=feast_repo_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfe8aae5",
   "metadata": {},
   "source": [
    "### Prompts\n",
    "\n",
    "Here we will set up a custom FeastPromptTemplate. This prompt template will take in a driver id, look up their stats, and format those stats into a prompt.\n",
    "\n",
    "Note that the input to this prompt template is just `driver_id`, since that is the only user defined piece (all other variables are looked up inside the prompt template).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9cee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, StringPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "594a3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"考虑到司机的最新统计数据，给他们写便条，将这些统计数据转发给他们。\n",
    "如果他们的谈话率高于 0.5, 请称赞他们。 否则，在最后开个玩笑让他们感觉更好\n",
    "\n",
    "以下是驱动程序统计数据：\n",
    "Conversation rate: {conv_rate}\n",
    "Acceptance rate: {acc_rate}\n",
    "Average Daily Trips: {avg_daily_trips}\n",
    "\n",
    "你的回应\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8464c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeastPromptTemplate(StringPromptTemplate):\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        driver_id = kwargs.pop(\"driver_id\")\n",
    "        feature_vector = store.get_online_features(\n",
    "            features=[\n",
    "                'driver_hourly_stats:conv_rate',\n",
    "                'driver_hourly_stats:acc_rate',\n",
    "                'driver_hourly_stats:avg_daily_trips'\n",
    "            ],\n",
    "            entity_rows=[{\"driver_id\": driver_id}]\n",
    "        ).to_dict()\n",
    "        kwargs[\"conv_rate\"] = feature_vector[\"conv_rate\"][0]\n",
    "        kwargs[\"acc_rate\"] = feature_vector[\"acc_rate\"][0]\n",
    "        kwargs[\"avg_daily_trips\"] = feature_vector[\"avg_daily_trips\"][0]\n",
    "        return prompt.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0c7bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = FeastPromptTemplate(input_variables=[\"driver_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8d70bb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureViewNotFoundException",
     "evalue": "Feature view driver_hourly_stats does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureViewNotFoundException\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(prompt_template\u001b[39m.\u001b[39;49mformat(driver_id\u001b[39m=\u001b[39;49m\u001b[39m1001\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36mFeastPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m      4\u001b[0m     driver_id \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mdriver_id\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     feature_vector \u001b[39m=\u001b[39m store\u001b[39m.\u001b[39;49mget_online_features(\n\u001b[1;32m      6\u001b[0m         features\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      7\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mdriver_hourly_stats:conv_rate\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mdriver_hourly_stats:acc_rate\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m             \u001b[39m'\u001b[39;49m\u001b[39mdriver_hourly_stats:avg_daily_trips\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     10\u001b[0m         ],\n\u001b[1;32m     11\u001b[0m         entity_rows\u001b[39m=\u001b[39;49m[{\u001b[39m\"\u001b[39;49m\u001b[39mdriver_id\u001b[39;49m\u001b[39m\"\u001b[39;49m: driver_id}]\n\u001b[1;32m     12\u001b[0m     )\u001b[39m.\u001b[39mto_dict()\n\u001b[1;32m     13\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mconv_rate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m feature_vector[\u001b[39m\"\u001b[39m\u001b[39mconv_rate\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39macc_rate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m feature_vector[\u001b[39m\"\u001b[39m\u001b[39macc_rate\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/feast/usage.py:299\u001b[0m, in \u001b[0;36mlog_exceptions_and_usage.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     ctx\u001b[39m.\u001b[39mtraceback \u001b[39m=\u001b[39m _trace_to_log(traceback)\n\u001b[1;32m    298\u001b[0m     \u001b[39mif\u001b[39;00m traceback:\n\u001b[0;32m--> 299\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m    301\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    302\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/feast/usage.py:288\u001b[0m, in \u001b[0;36mlog_exceptions_and_usage.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m ctx\u001b[39m.\u001b[39mattributes\u001b[39m.\u001b[39mupdate(attrs)\n\u001b[1;32m    287\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[39mif\u001b[39;00m ctx\u001b[39m.\u001b[39mexception:\n\u001b[1;32m    291\u001b[0m         \u001b[39m# exception was already recorded\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/feast/feature_store.py:1583\u001b[0m, in \u001b[0;36mFeatureStore.get_online_features\u001b[0;34m(self, features, entity_rows, full_feature_names)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1581\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll entity_rows must have the same keys.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m-> 1583\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_online_features(\n\u001b[1;32m   1584\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   1585\u001b[0m     entity_values\u001b[39m=\u001b[39;49mcolumnar,\n\u001b[1;32m   1586\u001b[0m     full_feature_names\u001b[39m=\u001b[39;49mfull_feature_names,\n\u001b[1;32m   1587\u001b[0m     native_entity_values\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1588\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/feast/feature_store.py:1646\u001b[0m, in \u001b[0;36mFeatureStore._get_online_features\u001b[0;34m(self, features, entity_values, full_feature_names, native_entity_values)\u001b[0m\n\u001b[1;32m   1639\u001b[0m num_rows \u001b[39m=\u001b[39m _validate_entity_values(entity_proto_values)\n\u001b[1;32m   1640\u001b[0m _validate_feature_refs(_feature_refs, full_feature_names)\n\u001b[1;32m   1641\u001b[0m (\n\u001b[1;32m   1642\u001b[0m     grouped_refs,\n\u001b[1;32m   1643\u001b[0m     grouped_odfv_refs,\n\u001b[1;32m   1644\u001b[0m     grouped_request_fv_refs,\n\u001b[1;32m   1645\u001b[0m     _,\n\u001b[0;32m-> 1646\u001b[0m ) \u001b[39m=\u001b[39m _group_feature_refs(\n\u001b[1;32m   1647\u001b[0m     _feature_refs,\n\u001b[1;32m   1648\u001b[0m     requested_feature_views,\n\u001b[1;32m   1649\u001b[0m     requested_request_feature_views,\n\u001b[1;32m   1650\u001b[0m     requested_on_demand_feature_views,\n\u001b[1;32m   1651\u001b[0m )\n\u001b[1;32m   1652\u001b[0m set_usage_attribute(\u001b[39m\"\u001b[39m\u001b[39modfv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mbool\u001b[39m(grouped_odfv_refs))\n\u001b[1;32m   1653\u001b[0m set_usage_attribute(\u001b[39m\"\u001b[39m\u001b[39mrequest_fv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mbool\u001b[39m(grouped_request_fv_refs))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/feast/feature_store.py:2486\u001b[0m, in \u001b[0;36m_group_feature_refs\u001b[0;34m(features, all_feature_views, all_request_feature_views, all_on_demand_feature_views)\u001b[0m\n\u001b[1;32m   2484\u001b[0m         request_view_refs\u001b[39m.\u001b[39madd(ref)\n\u001b[1;32m   2485\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2486\u001b[0m         \u001b[39mraise\u001b[39;00m FeatureViewNotFoundException(view_name)\n\u001b[1;32m   2488\u001b[0m fvs_result: List[Tuple[FeatureView, List[\u001b[39mstr\u001b[39m]]] \u001b[39m=\u001b[39m []\n\u001b[1;32m   2489\u001b[0m odfvs_result: List[Tuple[OnDemandFeatureView, List[\u001b[39mstr\u001b[39m]]] \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mFeatureViewNotFoundException\u001b[0m: Feature view driver_hourly_stats does not exist"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(driver_id=1001))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2870d070",
   "metadata": {},
   "source": [
    "### Use in a chain\n",
    "\n",
    "We can now use this in a chain, successfully creating a chain that achieves personalization backed by a feature store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7106255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79543326",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=ChatOpenAI(), prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97a741a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi there! I wanted to update you on your current stats. Your acceptance rate is 0.055561766028404236 and your average daily trips are 936. While your conversation rate is currently 0.4745151400566101, I have no doubt that with a little extra effort, you'll be able to exceed that .5 mark! Keep up the great work! And remember, even chickens can't always cross the road, but they still give it their best shot.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(1001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4049990-651d-44d3-82b1-0cd122da55c1",
   "metadata": {},
   "source": [
    "## Tecton\n",
    "\n",
    "Above, we showed how you could use Feast, a popular open source and self-managed feature store, with LangChain. Our examples below will show a similar integration using Tecton. Tecton is a fully managed feature platform built to orchestrate the complete ML feature lifecycle, from transformation to online serving, with enterprise-grade SLAs.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bb4dba1-0678-4ea4-be0a-d353c0b13fc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prerequisites\n",
    "\n",
    "- Tecton Deployment (sign up at [https://tecton.ai](https://tecton.ai))\n",
    "- `TECTON_API_KEY` environment variable set to a valid Service Account key\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac9eb618-8c52-4cd6-bb8e-9c99a150dfa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define and Load Features\n",
    "\n",
    "We will use the user_transaction_counts Feature View from the [Tecton tutorial](https://docs.tecton.ai/docs/tutorials/tecton-fundamentals) as part of a Feature Service. For simplicity, we are only using a single Feature View; however, more sophisticated applications may require more feature views to retrieve the features needed for its prompt.\n",
    "\n",
    "```python\n",
    "user_transaction_metrics = FeatureService(\n",
    "    name = \"user_transaction_metrics\",\n",
    "    features = [user_transaction_counts]\n",
    ")\n",
    "```\n",
    "\n",
    "The above Feature Service is expected to be [applied to a live workspace](https://docs.tecton.ai/docs/applying-feature-repository-changes-to-a-workspace). For this example, we will be using the \"prod\" workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32e9675d-a7e5-429f-906f-2260294d3e46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tecton\n",
    "\n",
    "workspace = tecton.get_workspace(\"prod\")\n",
    "feature_service = workspace.get_feature_service(\"user_transaction_metrics\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29b7550c-0eb4-4bd1-a501-1c63fb77aa56",
   "metadata": {},
   "source": [
    "### Prompts\n",
    "\n",
    "Here we will set up a custom TectonPromptTemplate. This prompt template will take in a user_id , look up their stats, and format those stats into a prompt.\n",
    "\n",
    "Note that the input to this prompt template is just `user_id`, since that is the only user defined piece (all other variables are looked up inside the prompt template).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fb77ea4-64c6-4e48-a783-bd1ece021b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, StringPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02a98fbc-8135-4b11-bf60-85d28e426667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Given the vendor's up to date transaction stats, write them a note based on the following rules:\n",
    "\n",
    "1. If they had a transaction in the last day, write a short congratulations message on their recent sales\n",
    "2. If no transaction in the last day, but they had a transaction in the last 30 days, playfully encourage them to sell more.\n",
    "3. Always add a silly joke about chickens at the end\n",
    "\n",
    "Here are the vendor's stats:\n",
    "Number of Transactions Last Day: {transaction_count_1d}\n",
    "Number of Transactions Last 30 Days: {transaction_count_30d}\n",
    "\n",
    "Your response:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a35cdfd5-6ccc-4394-acfe-60d53804be51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TectonPromptTemplate(StringPromptTemplate):\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        user_id = kwargs.pop(\"user_id\")\n",
    "        feature_vector = feature_service.get_online_features(join_keys={\"user_id\": user_id}).to_dict()\n",
    "        kwargs[\"transaction_count_1d\"] = feature_vector[\"user_transaction_counts.transaction_count_1d_1d\"]\n",
    "        kwargs[\"transaction_count_30d\"] = feature_vector[\"user_transaction_counts.transaction_count_30d_1d\"]\n",
    "        return prompt.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5915df0-fb16-4770-8a82-22f885b74d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = TectonPromptTemplate(input_variables=[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a36abfc8-ea60-4ae0-a36d-d7b639c7307c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the vendor's up to date transaction stats, write them a note based on the following rules:\n",
      "\n",
      "1. If they had a transaction in the last day, write a short congratulations message on their recent sales\n",
      "2. If no transaction in the last day, but they had a transaction in the last 30 days, playfully encourage them to sell more.\n",
      "3. Always add a silly joke about chickens at the end\n",
      "\n",
      "Here are the vendor's stats:\n",
      "Number of Transactions Last Day: 657\n",
      "Number of Transactions Last 30 Days: 20326\n",
      "\n",
      "Your response:\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(user_id=\"user_469998441571\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8d4b905-1051-4303-9c33-8eddb65c1274",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use in a chain\n",
    "\n",
    "We can now use this in a chain, successfully creating a chain that achieves personalization backed by the Tecton Feature Platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ffb60cd0-8e3c-4c9d-b639-43d766e12c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3918abc7-00b5-466f-bdfc-ab046cd282da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=ChatOpenAI(), prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e7d91c4b-3e99-40cc-b3e9-a004c8c9193e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow, congratulations on your recent sales! Your business is really soaring like a chicken on a hot air balloon! Keep up the great work!'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"user_469998441571\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752b924-caf9-4f7a-b78b-cb8c8ada8c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0691cd9",
   "metadata": {},
   "source": [
    "## Featureform\n",
    "\n",
    "Finally, we will use [Featureform](https://github.com/featureform/featureform) an open-source and enterprise-grade feature store to run the same example. Featureform allows you to work with your infrastructure like Spark or locally to define your feature transformations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44320d68",
   "metadata": {},
   "source": [
    "### Initialize Featureform\n",
    "\n",
    "You can follow in the instructions in the README to initialize your transformations and features in Featureform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64ada9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import featureform as ff\n",
    "\n",
    "client = ff.Client(host=\"demo.featureform.com\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b28914a2",
   "metadata": {},
   "source": [
    "### Prompts\n",
    "\n",
    "Here we will set up a custom FeatureformPromptTemplate. This prompt template will take in the average amount a user pays per transactions.\n",
    "\n",
    "Note that the input to this prompt template is just avg_transaction, since that is the only user defined piece (all other variables are looked up inside the prompt template).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, StringPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88253bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given the amount a user spends on average per transaction, let them know if they are a high roller. Otherwise, make a silly joke about chickens at the end to make them feel better\n",
    "\n",
    "Here are the user's stats:\n",
    "Average Amount per Transaction: ${avg_transcation}\n",
    "\n",
    "Your response:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f72476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureformPromptTemplate(StringPromptTemplate):\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        user_id = kwargs.pop(\"user_id\")\n",
    "        fpf = client.features([(\"avg_transactions\", \"quickstart\")], {\"user\": user_id})\n",
    "        return prompt.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = FeatureformPrompTemplate(input_variables=[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b2b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_template.format(user_id=\"C1410926\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f09ddfdd",
   "metadata": {},
   "source": [
    "### Use in a chain\n",
    "\n",
    "We can now use this in a chain, successfully creating a chain that achieves personalization backed by the Featureform Feature Platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=ChatOpenAI(), prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5412626",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"C1410926\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
