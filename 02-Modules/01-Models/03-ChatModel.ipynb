{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "该笔记本介绍了如何开始使用聊天模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4433afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys               \n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"..\"))) \n",
    "from API_KEYS import InitAzureEnv,AzureDeploymentName\n",
    "\n",
    "InitAzureEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522686de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = AzureChatOpenAI(\n",
    "    deployment_name=AzureDeploymentName.CHAT,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbaec18e-3684-4eef-955f-c1cec8bf765d",
   "metadata": {},
   "source": [
    "您可以通过将一条或多条消息传递给聊天模型来获得聊天完成。响应将是一条消息。`LangChain` 目前支持的消息类型有`AIMessage`, `HumanMessage`, `SystemMessage`, 和`ChatMessage–ChatMessage`接受任意角色参数。大多数时候，你只会处理`HumanMessage`, `AIMessage`, 和`SystemMessage`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a6e7b0-e927-4bfb-a414-1332a4149106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I like programming.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([HumanMessage(content=\"把这段话从中文翻译为英文:我喜欢编程\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a62153d4-1211-411b-a493-3febfe446ae0",
   "metadata": {},
   "source": [
    "OpenAI 的聊天模型支持多条消息作为输入。有关更多信息，请参见[此处](https://platform.openai.com/docs/guides/chat/chat-vs-completions)。以下是向聊天模型发送系统和用户消息的示例：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce16ad78-8e6f-48cd-954e-98be75eb5836",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I like programming.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"你是一个翻译助理，如果对方说的是中文，你要他说的话翻译为英文\"),\n",
    "    HumanMessage(content=\"我喜欢编程.\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36dc8d7e-bd25-47ac-8c1b-60e3422603d3",
   "metadata": {},
   "source": [
    "您可以更进一步，使用`generate`为多组消息生成补全信息。这将返回 LLMResult 带有附加 message 参数的 。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b21fc52-74b6-4950-ab78-45d12c68fb4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='I like programming.', generation_info=None, message=AIMessage(content='I like programming.', additional_kwargs={}, example=False))], [ChatGeneration(text='I like watching movies.', generation_info=None, message=AIMessage(content='I like watching movies.', additional_kwargs={}, example=False))]], llm_output={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 115, 'total_tokens': 124}, 'model_name': 'gpt-3.5-turbo'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"你是一个翻译助理，如果对方说的是中文，你要他说的话翻译为英文.\"),\n",
    "        HumanMessage(content=\"我喜欢编程.\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"你是一个翻译助理，如果对方说的是中文，你要他说的话翻译为英文.\"),\n",
    "        HumanMessage(content=\"我喜欢看电影.\")\n",
    "    ],\n",
    "]\n",
    "result = chat.generate(batch_messages)\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2960f50f",
   "metadata": {},
   "source": [
    "您可以从此`LLMResult`中查看`token`使用之类的内容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6186bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 9,\n",
       "  'prompt_tokens': 115,\n",
       "  'total_tokens': 124},\n",
       " 'model_name': 'gpt-3.5-turbo'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b10b00ef-f373-4bc3-8302-2dfc28033734",
   "metadata": {},
   "source": [
    "## PromptTemplates\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "778f912a-66ea-4a5d-b3de-6c7db4baba26",
   "metadata": {},
   "source": [
    "您可以通过使用`MessagePromptTemplate`从一个或多个构建一个`MessagePromptTemplates`。您可以使用`ChatPromptTemplate`的`format_prompt`返回一个`PromptValue`，您可以将其转换为字符串或`Message`对象，具体取决于您是要使用格式化值作为`llm`还是聊天模型的输入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "180c5cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I like programming.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_msg_prompt = SystemMessagePromptTemplate.from_template(\"你是是一个翻译助手，请将 {input_language} 翻译为 {output_language}.\")\n",
    "human_msg_prompt = HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_msg_prompt, human_msg_prompt])\n",
    "chat(chat_prompt.format_prompt(input_language=\"中文\", output_language=\"英文\", text=\"我喜欢编程\").to_messages())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e28b98da",
   "metadata": {},
   "source": [
    "如果想更直接的构造 MessagePromptTemplate，可以在外面创建一个 PromptTemplate，然后传入，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b1ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "    input_variables=[\"input_language\", \"output_language\"],\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate(prompt=prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92af0bba",
   "metadata": {},
   "source": [
    "## LLMChain\n",
    "\n",
    "您可以使用与之前非常相似的方式使用现有的`LLMChain`提供一个提示和模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2cbfe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=chat, prompt=chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268543b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like programming.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_language=\"正文\", output_language=\"英文\", text=\"我喜欢编程.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb779f3f",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Streaming is supported for `ChatOpenAI` through callback handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509181be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 周润发\n",
      "2. 梁朝伟\n",
      "3. 张国荣\n",
      "4. 刘德华\n",
      "5. 王家卫\n",
      "6. 林青霞\n",
      "7. 张曼玉\n",
      "8. 汤姆·克鲁斯\n",
      "9. 吴彦祖\n",
      "10. 古天乐\n",
      "11. 陈奕迅\n",
      "12. 周星驰\n",
      "13. 李连杰\n",
      "14. 成龙\n",
      "15. 姜文\n",
      "16. 刘青云\n",
      "17. 谢霆锋\n",
      "18. 郑伊健\n",
      "19. 余文乐\n",
      "20. 黄秋生"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "chat = AzureChatOpenAI(\n",
    "    streaming=True, \n",
    "    callbacks=[StreamingStdOutCallbackHandler()], \n",
    "    temperature=0,\n",
    "    deployment_name=AzureDeploymentName.CHAT\n",
    ")\n",
    "resp = chat([HumanMessage(content=\"香港有哪些著名的电影演员?\")])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84e76c6c",
   "metadata": {},
   "source": [
    "## 提供一些镜头示例\n",
    "\n",
    "### 交替的人类/人工智能信息\n",
    "\n",
    "进行少量镜头提示的第一种方法依赖于使用交替的人/人工智能信息。请参阅下面的示例。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6b7ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"你是一个翻译助理，如果对方说的是中文，你要他说的话翻译为英文.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "example_human = SystemMessagePromptTemplate.from_template(\"你好\", additional_kwargs={\"name\": \"example_human\"})\n",
    "example_ai = SystemMessagePromptTemplate.from_template(\"Hi\", additional_kwargs={\"name\": \"example_ai\"})\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "644d4e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy programming."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I enjoy programming.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, example_human, example_ai, human_message_prompt])\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "# get a chat completion from the formatted messages\n",
    "chain.run(\"我喜欢编程.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
